---
title: Marcel C. Buehler
position: PhD Candidate
image: assets/people/buehler.jpg
email: marcel.buehler@inf.ethz.ch
phone:
address: Stampfenbachstrasse 48, 8092 ZÃ¼rich, Switzerland
office: ETH Zurich, Department of Computer Science, <a class="a-text-ext"
                                                       href="http://www.mapsearch.ethz.ch/map/mapSearchPre.do?farbcode=c010&amp;lang=EN&amp;raumMap=56&amp;gebaeudeMap=STD"
                                                       target="_blank" title="Building Information">STD</a>, <a
        class="a-text-ext"
        href="https://www.rauminfo.ethz.ch/Rauminfo/grundrissplan.gif?gebaeude=STD&geschoss=G&raumNr=28&lang=EN"
        target="_blank" title="Room Information">G 28</a>
website:
cv:

---
<h2>Biography and Research </h2>
<p>I conducted my PhD in the <a class="a-text-ext" href="https://ait.ethz.ch/"
                                title="Advanced Interactive Technologies" target="_blank">Advanced Interactive
    Technologies</a>
    lab of the <a class="a-text-ext" href="https://iis.inf.ethz.ch/"
                  title="Institute for Intelligent Interactive Systems" target="_blank">Institute for Intelligent
        Interactive Systems</a>
    at <a class="a-text-ext" href="http://www.ethz.ch/" target="_blank">ETH Zurich</a>,
    supervised by <a class="a-text-ext" target="_blank" href="people/hilliges/"
                     title="Professor Otmar Hilliges">Prof. Otmar Hilliges</a>,
    <a class="a-text-ext" target="_blank" href="https://thabobeeler.com/" title="Thabo Beeler">Dr. Thabo Beeler</a>, and <a class="a-text-ext" target="_blank" href="https://cgl.ethz.ch/people/grossm/about/home.php"
                                                                                                                        title="Professor Markus Gross">Prof. Markus Gross</a>.
    In August 2025, I defended my <a href="https://www.research-collection.ethz.ch/entities/publication/b41e5046-1874-47b1-a5ad-5cdaaa6e2133" target="_blank" title="Thesis">
        PhD thesis</a> titled <i>Faithful 3D Avatars for Everyone: Prior-Guided Face Reconstruction for High-Quality Novel View Synthesis from Casual Few-Shot Captures</i>
    to an international committee with Prof. Markus Gross (ETH Zurich), Dr. Thabo Beeler (Google),
    <a class="a-text-ext" target="_blank" href="https://www.cs.cmu.edu/~ftorre/" title="Prof. Fernando De la Torre">Prof. Fernando De la Torre</a>
    (<a class="a-text-ext" target="_blank" href="http://www.humansensing.cs.cmu.edu/" title="Carnegie Mellon University">Carnegie Mellon University</a>) and
    <a class="a-text-ext" target="_blank" href="https://web.stanford.edu/~gordonwz/" title="Prof. Gordon Wetzstein">Prof. Gordon Wetzstein</a>
    (<a class="a-text-ext" target="_blank" href="https://web.stanford.edu" title="Stanford University">Stanford University</a>).
    </p>
    <p>
    From May 2024 to June 2025, I conducted research as intern at <a class="a-text-ext" target="_blank"
                                                         href="https://research.nvidia.com/labs/lpr/"
                                                         title="Nvidia Learning and Perception">Nvidia's</a>
    <a class="a-text-ext" target="_blank"
       href="https://research.nvidia.com/labs/dair/"
       title="Nvidia Data-Driven AI for Robotics">Data-Driven AI for Robotics</a> group.
    From July 2022 to May 2024, I was a Student Researcher at <a
            class="a-text-ext" href="https://arvr.google.com/" title="Google AR/VR" target="_blank">Google AR/VR</a>.

    I obtained my Master's degree in Data Science from ETH Zurich in 2020 and my Bachelor's degree in Computer
    Science from
    <a class="a-text-ext" target="_blank" href="https://www.uzh.ch" title="University of Zurich">University of
        Zurich</a> in 2017.
</p>
<p>
    My research enables to reconstruct personalized, high-quality 3D avatars from just a few smartphone photos.
    3D avatar reconstruction from sparse inputs requires resolving fundamental ambiguities.
    Inspired by how humans use prior knowledge, I research how statistical and neural priors can be injected into neural
    models to facilitate high-quality, faithful reconstructions.
    Specifically, I develop neural models of 3D avatars trained on large-scale real and synthetic datasets for novel view synthesis up to 4K resolution.
    These models enable important applications for AR/VR like telepresence, entertainment, and fashion.</p>
<p>
    <b>Keywords</b>: 3D avatars; sparse inputs; generative models; differentiable rendering; NeRF; 3D Gaussian Splatting; disentanglement.

</p>
<br/>
<b>Links:</b>
<ul>
    <li><a href="https://scholar.google.com/citations?user=6PWhhPsAAAAJ&hl=" target="_blank">Google Scholar</a></li>
    <li><a href="https://www.linkedin.com/in/mcbuehler" target="_blank">LinkedIn</a></li>
    <li><a href="https://github.com/mcbuehler" target="_blank">GitHub</a></li>
    <li><a href="https://www.youtube.com/@marcelbuhler4593" target="_blank">Youtube</a></li>
</ul>

<h2>Publications </h2>

{% include get-publications.html filter="person" key="Buehler" full-width=true %}


<h3>Activities</h3>
<h4>Reviewing</h4>
<dl class="thesislist">
    <dt>2026</dt>
    <dd>
        <a class="a-text-ext" href="https://cvpr.thecvf.com/Conferences/2026" target="_blank">CVPR</a>,
        <a class="a-text-ext" href="https://3dvconf.github.io/2026/" target="_blank">3DV</a>
    </dd>
    <dt>2025</dt>
    <dd>
        <a class="a-text-ext" href="https://asia.siggraph.org/2025/" target="_blank">SIGGRAPH Asia</a>,
        <a class="a-text-ext" href="https://neurips.cc/Conferences/2025" target="_blank">NeurIPS</a>,
        <a class="a-text-ext" href="https://acmmm2025.org/" target="_blank">ACM Multimedia</a>,
        <a class="a-text-ext" href="https://iccv2025.thecvf.com/" target="_blank">ICCV</a>,
        <a class="a-text-ext" href="https://cvpr.thecvf.com/" target="_blank"><object type="image/svg+xml" data="https://ait.ethz.ch/assets/icons/award.svg"></object> CVPR (Outstanding reviewer)</a>
    </dd>
    <dt>2024</dt>
    <dd><a class="a-text-ext" href="https://cvpr.thecvf.com/" target="_blank">CVPR</a>,
        <a class="a-text-ext" href="https://gazeworkshop.github.io/2024/" target="_blank">CVPRW Gaze Workshop</a>,
        <a class="a-text-ext" href="https://eccv2024.ecva.net/" target="_blank">ECCV</a>,
        <a class="a-text-ext" href="https://asia.siggraph.org/2024/" target="_blank">SIGGRAPH Asia</a>,
        <a class="a-text-ext" href="https://dl.acm.org/journal/tog" target="_blank">ACM Transaction on Graphics</a>,
        TPAMISI
    </dd>
    <dt>2023</dt>
    <dd>
        <a class="a-text-ext" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34"
           target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>,
        <a class="a-text-ext" href="https://cvpr2023.thecvf.com/" target="_blank"><object type="image/svg+xml" data="https://ait.ethz.ch/assets/icons/award.svg"></object> CVPR (Outstanding reviewer)</a>,
        <a class="a-text-ext" href="https://gazeworkshop.github.io/2023/" target="_blank">CVPRW Gaze Workshop</a>,
        <a class="a-text-ext" href="https://iccv2023.thecvf.com/" target="_blank">ICCV</a>,
        <a class="a-text-ext" href="https://s2023.siggraph.org/" target="_blank">SIGGRAPH</a>
    </dd>
    <dt>2022</dt>
    <dd>
        <a class="a-text-ext" href="https://cvpr2022.thecvf.com/" target="_blank">CVPR</a>,
        <a class="a-text-ext" href="https://eccv2022.ecva.net/" target="_blank">ECCV</a>
    </dd>
    <dt>2021</dt>
    <dd>
        <a class="a-text-ext" href="http://iccv2021.thecvf.com/" target="_blank">ICCV</a>,
        <a class="a-text-ext" href="https://gazeworkshop.github.io/2021/" target="_blank">GAZE</a> workshop at
        <a class="a-text-ext" href="http://cvpr2021.thecvf.com/" target="_blank">CVPR</a></dd>
    <dt>2020</dt>
    <dd>
        <a class="a-text-ext" href="https://openeyes-workshop.github.io/" target="_blank">OpenEyes</a> workshop at
        <a class="a-text-ext" href="https://eccv2020.eu/" target="_blank">ECCV</a>
    </dd>
</dl>
<br/>

<h4>Talks</h4>
<dl class="thesislist">
    <dt>2025</dt>
    <dd><a class="a-text-ext" href="https://www.niessnerlab.org/"
           title="Visual Computing & Artificial Intelligence Lab at TUM" target="_blank">Visual Computing & Artificial Intelligence Lab</a>
        at <a class="a-text-ext" href="https://www.tum.de/en/" target="_blank">TU Munich</a>
    </dd>
    <dd><a class="a-text-ext" href="https://justusthies.github.io/"
           title="3D Graphics & Vision at TUD" target="_blank">3D Graphics & Vision Lab</a>
        at <a class="a-text-ext" href="https://www.tu-darmstadt.de/" target="_blank">TU Darmstadt</a>
    </dd>
    <dd><a class="a-text-ext" href="https://www.vis.uni-stuttgart.de/en/research_group/computer_vision/"
           title="Computer Vision Research Group" target="_blank">Computer Vision Research Group</a>
        at <a class="a-text-ext" href="https://www.uni-stuttgart.de/en/" target="_blank">University of Stuttgart</a>
    </dd>
    <dt>2022</dt>
    <dd><a class="a-text-ext" href="https://people.eecs.berkeley.edu/~kanazawa/"
           title="Kanazawa AI Research Lab (KAIR)" target="_blank">Kanazawa AI Research Lab</a>
        at <a class="a-text-ext" href="https://www.berkeley.edu/" target="_blank">UC Berkeley</a>
    </dd>
    <dt>2020</dt>
    <dd><a class="a-text-ext" href="https://biomedicalcomputervision.uniandes.edu.co/"
           title="Biomedical Computer Vision Group" target="_blank">Biomedical Computer Vision Group</a>
        at <a class="a-text-ext" href="https://uniandes.edu.co/" target="_blank">Universidad de los Andes</a>
    </dd>
    <dt>2019</dt>
    <dd><a class="a-text-ext"
           href="https://research.fb.com/programs/the-2019-openeds-workshop-eye-tracking-for-vr-and-ar/"
           title="Eye Tracking for VR and AR" target="_blank">Eye Tracking for VR and AR</a> workshop at
        <a class="a-text-ext" href="https://iccv2019.thecvf.com/" title="ICCV" target="_blank">ICCV</a>
    <dd><a class="a-text-ext" href="https://futurict2.eu/150-students-hackathon-beth-2019/" title="BETH Hackathon"
           target="_blank">BETH Hackathon</a> at <a class="a-text-ext" href="http://www.ethz.ch/" target="_blank">ETH
        Zurich</a></dd>
    <dt>2018</dt>
    <dd><a class="a-text-ext"
           href="https://incubechallenge.com/2018/11/22/incube-2018-from-inside-a-leap-into-the-challenge/"
           title="InCube Hackathon" target="_blank">InCube Hackathon</a> at <a class="a-text-ext"
                                                                               href="http://www.ethz.ch/"
                                                                               target="_blank">ETH Zurich</a>
    </dd>
</dl>
<br/>

<h4>Teaching</h4>
<dl class="thesislist">
    <dt>2025</dt>
    <dd><a href="https://ait.ethz.ch/teaching/courses/2025-ss-machine-perception" target="_blank"
           title="Machine Perception">Machine Perception</a> (Lecturer),
        <a href="https://ait.ethz.ch/teaching/courses/2025-ss-seminar-human-performance-capture" target="_blank"
           title="Seminar on Human-Performance Capture">Seminar on Human-Performance Capture</a> (TA)
    </dd>
    <dt>2024</dt>
    <dd><a href="https://ait.ethz.ch/teaching/courses/2024-ss-machine-perception" target="_blank"
           title="Machine Perception">Machine Perception</a> (Lecturer),
        <a href="https://ait.ethz.ch/teaching/courses/2024-ss-seminar-human-performance-capture" target="_blank"
           title="Seminar on Human-Performance Capture">Seminar on Human-Performance Capture</a> (TA)
    </dd>
    <dt>2023</dt>
    <dd><a href="https://ait.ethz.ch/teaching/courses/2023-SS-Machine-Perception" target="_blank"
           title="Machine Perception">Machine Perception</a> (Head TA)
    </dd>
    <dt>2022</dt>
    <dd><a href="https://ait.ethz.ch/teaching/courses/2022-SS-Machine-Perception" target="_blank"
           title="Machine Perception">Machine Perception</a> (Head TA)
    </dd>
    <dt>2021</dt>
    <dd>Informatik I, Informatik II</dd>
</dl>
<br/>

<h4>Research Internships</h4>
<dl class="thesislist">
    <dt>2025</dt>
    <dd><a class="a-text-ext" href="https://research.nvidia.com/labs/lpr/"
           title="NVIDIA Learning and Perception Research Group" target="_blank">NVIDIA Learning and Perception Research
        Group, Zurich</a>
    </dd>
    <dt>2024</dt>
    <dd><a class="a-text-ext" href="https://research.nvidia.com/labs/lpr/"
           title="NVIDIA Learning and Perception Research Group" target="_blank">NVIDIA Learning and Perception Research
        Group, Santa Clara</a>
    </dd>
    <dt>2023 - 2024</dt>
    <dd><a class="a-text-ext" href="https://arvr.google.com/" title="Google AR/VR" target="_blank">Google AR/VR,
        Zurich</a>
    </dd>
    <dt>2022</dt>
    <dd><a class="a-text-ext" href="https://arvr.google.com/" title="Google AR/VR" target="_blank">Google AR/VR, San
        Francisco</a>
    </dd>
</dl>
<br/>

<h4>Volunteering</h4>
<dl class="thesislist">
    <dt>2024 - present</dt>
    <dd><a class="a-text-ext"
           href="https://www.alumni.ethz.ch/en/welcome/mitgliederorganisationen/club/entrepreneur-alumni.html"
           title="ETH Entrepreneur Alumni" target="_blank">ETH Entrepreneur Alumni</a> (Co-president)
    </dd>
    <dt>2023 - 2024</dt>
    <dd><a class="a-text-ext"
           href="https://www.alumni.ethz.ch/en/welcome/mitgliederorganisationen/club/entrepreneur-alumni.html"
           title="ETH Entrepreneur Alumni" target="_blank">ETH Entrepreneur Alumni</a> (Board Member)
    </dd>
</dl>
<br/>

