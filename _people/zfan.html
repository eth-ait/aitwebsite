---
title: Zicong Fan
position: PhD Student
image: assets/people/zfan.jpg    
phone: 
website: https://zc-alexfan.github.io
address: Stampfenbachstrasse 48, 8092 ZÃ¼rich, Switzerland
office: ETH Zurich, Department of Computer Science, <a class="a-text-ext" href="http://www.mapsearch.ethz.ch/map/mapSearchPre.do?farbcode=c010&amp;lang=EN&amp;raumMap=56&amp;gebaeudeMap=STD" target="_blank" title="Building Information">STD</a>, <a class="a-text-ext" href="http://www.rauminfo.ethz.ch/Rauminfo/grundrissplan.gif?gebaeude=STD&amp;geschoss=H&amp;raumNr=29.1&amp;lang=EN" target="_blank" title="Room Information">H 25</a>
website: 
cv:

---

<div id="email-placeholder" style="cursor: pointer; color: blue;">Click here to view my email (javascript required); I only supervise ETHZ/UZH students</div>
<div id="feedback" style="color: green; display: none;">Email copied to clipboard!</div>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RJ93D4865V"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-RJ93D4865V');
</script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    var user0 = 'zicon';
    var user1 = 'g.fan';

    var domain0 = 'inf.e';
    var domain1 = 'thz.ch';
    var email = user0 + user1 + '@' + domain0 + domain1;

    var emailPlaceholder = document.getElementById('email-placeholder');
    var feedbackMessage = document.getElementById('feedback');
    var emailRevealed = false;

    emailPlaceholder.addEventListener('click', function() {
        // Check if email is already revealed
        if (!emailRevealed) {
            // Replace placeholder text with the email address
            emailPlaceholder.textContent = email;
            emailRevealed = true;

            // Copy the email address to the clipboard
            navigator.clipboard.writeText(email).then(function() {
                // Show feedback message
                feedbackMessage.style.display = 'block';

                // Hide the feedback message after 2 seconds
                setTimeout(function() {
                    feedbackMessage.style.display = 'none';
                }, 2000);
            }).catch(function(error) {
                // Handle any errors
                console.error('Error copying email to clipboard', error);
            });
        }
    });
});

</script>


<h2>Biography </h2>
    <p> I am a doctoral student at ETH supervised by Professor <a class="a-text-ext" href="https://ait.ethz.ch/people/hilliges/" target="_blank">Otmar Hilliges</a> and Professor <a class="a-text-ext" href="https://ps.is.mpg.de/~black" target="_blank">Michael J. Black</a>. Before starting my Ph.D., I finished my B.Sc. (2018) and M.Sc. (2020) in Computer Science at <a class="a-text-ext" href="https://www.cs.ubc.ca/" target="_blank"> The University of British Columbia</a>, Vancouver, Canada. In my Masters, I worked in vision + language problems (e.g., visual grounding, visual commonsense reasoning) with Professor <a class="a-text-ext" href="https://www.cs.ubc.ca/~lsigal/" target="_blank">Leonid Sigal</a> and Professor <a class="a-text-ext" href="https://www.cs.ubc.ca/~little/" target="_blank">Jim Little</a>.
    </p>
    
<h2>Research Interests</h2>
<p>
    My main research interests lie in computer vision and machine learning. These include topics such as hand pose estimation, human pose estimation and modelling the interaction of human-objects and human-scene. I am also interested in egocentric computer vision.
</p>

<h2>Research Opportunity for Prospective Master's Students</h2>
<p>
<b>Introduction:</b> 3D hand pose/shape estimation and the modeling of human/object interaction is a pathway to real-world interactive AR/VR applications such as Microsofts HoloLens and Facebooks Occulus Rift. The reason is that we interact with the world using our hands to use tools and to socialize with others.
</p>

<p>
<b>Research Directions:</b> My main research interests lie in computer vision and machine learning, including but not limited to topics such as hand pose estimation, human pose estimation, and modeling the interaction of human-objects and human-scene. Currently, I offer two research streams: 1) Estimating 3d hand pose/shape from images; 2) Modelling the interaction of humans and objects. A stream-1 project could be devising a semi-supervised method for hand pose/shape estimation from <a href="https://arxiv.org/pdf/2012.09856.pdf">in-the-wild</a> egocentric images such as from datasets like <a href="https://epic-kitchens.github.io/">Epic-Kitchens</a>. A stream-2 project could be creating a new task for the newly released <a href="https://arctic.is.tue.mpg.de">ARCTIC dataset</a>, which captures human-object interactions.
</p>

<p>
<b>Requirements:</b> I am looking for independent and highly motivated students who should have taken a recognized deep learning or a modern computer vision course (e.g., Machine Perception) and should be skilled in Python and PyTorch. The projects are research-oriented, and I encourage students to submit to top-tier computer vision conferences. I work closely with students during their projects as it is a great way for both of us to learn, and I would love to provide feedback and assistance for their projects.
</p>

<p>
<i>Should you be interested in these areas or would like to know more, do not hesitate to contact me. P.S. students are encouraged (but not required) to bring their own ideas.</i>
</p>

<p>
<b>Keywords:</b> computer vision, VR/AR, 3D reconstruction, 3D pose estimation, machine learning, neural networks, human-object interactions
</p>

<h2>Publications </h2>

{% include get-publications.html filter="person" key="Zicong Fan" full-width=true %}
