---
title: Advanced Topics in Human-Centric Computer Vision
ref: athccv2024
description: 
semester: Fall 2024
number: <a href="https://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?lerneinheitId=183343&semkez=2024W&ansicht=LEHRVERANSTALTUNGEN&lang=en">263-3713-00L</a>
lecturer: Jie Song
head-ta: Chengwei Zheng 
ta: Juan Zarate, Manuel Kaufmann, Egor Zakharov, Gengyan Li, Zicong Fan, Yufeng Zheng, Zijian Dong, Mert Albaba, Lixin Xue, Vanessa Sklyarova, Tianjian Jiang 
assistants:
edoz: 
session-time-place: Thu 16:15 - 18:00 pm, CAB G56
lecture-time-place: 
exercise-time-place: 
image: 
links: 
credits: 2
---
<!--
template: <a href="https://docs.google.com/document/d/1Ezq_c-wVejgQh-JpD_lz9JncmLfTEcgZNCB-9NA23UU/edit">Review template</a>
--> 
<h3>Overview</h3>
<p>
    The learning objective is to analyze selected research papers published at top computer vision and machine learning venues. A key focus will be placed on identifying and discussing open problems and novel solutions in this space. The seminar will achieve this via several components: reading papers, technical presentations, writing analysis and critique summaries, class discussions, and exploration of potential research topics. In this seminar we will discuss state-of-the-art literature on human-centric computer vision topics including but not limited to human pose estimation, hand and eye-gaze estimation as well as generative modeliing of detailed human activities.
</p>

<hr/>

<h3>Goal</h3>
<p>The goal of the seminar is not only to familiarize students with exciting new research topics, but also to teach basic scientific writing and oral presentation skills. The seminar will have a different structure from regular seminars to encourage more discussion and a deeper learning experience.
</p>

<p>We will treat papers as case studies and discuss them in-depth in the seminar. Once per semester, every student will have to take one of the following roles: </p>
<ol>
    <li><b>Presenter</b>: Give a presentation about the paper that you read in depth.</li>
    <li><b>Reviewer</b>: Write a critical review of the paper following <a href="https://docs.google.com/document/d/1Ezq_c-wVejgQh-JpD_lz9JncmLfTEcgZNCB-9NA23UU/edit"> this template</a>.
</ol>
<p>All other students read the paper and submit questions they have about the paper before the presentation.</p>

<!-- 
<p>We will use a case-study format where all students read the same paper each week but fulfill different roles and hence prepare with different viewpoints in mind.</p>
<b>Student roles</b>:
<ol>
    <li><b>Historian</b>: Find out how this paper sits in the context of the related work. Use bibliography tools to find the most influential papers cited by this work and at least one paper influenced by the work (and summarize the two papers). </li>
    <li><b>Presenter</b>: Give a <i>short</i> presentation about the paper that you read in depth.</li>
    <li><b>Reviewer</b>: Complete a full critical review of the paper. Use the original review from and come to a recommendation whether the paper should be accepted or not.</li>
    <li><b>PhD student</b>: Propose a follow-up project for your own research based on this paper - importantly the project should be directly inspired by the paper or even use/extend the method proposed.</li>
    <li><b>Journalist</b>: After the presentation, write an article about the the paper that can be understood by the general public; include points from the general discussion during the seminar, the historian, or the PhD student
    <li><b>All students</b> (every week): Come up with an alternative title; did the paper miss anything? </li>
</ol>
<br/>-->
<!-- <p> Attendance in the weekly meetings is mandatory.</p> -->
<hr/>


<!--

<a class="anchor" id="schedule"></a>
<h3>Schedule</h3>

<table><tbody>
  <tr><th>Wk.</th>    <th>Date</th>       <th>TA</th>                   <th>Paper</th>
  <tr><td>1</td>      <td>21.09.2023</td> <td><h5> -- </h5>             <td>no seminar</td></tr>
                                                              
  <tr><td>2</td>      <td>28.09.2023</td> <td><h5> -- </h5>             <td>no seminar</td></tr>

  <tr><td>3</td>      <td>05.10.2023</td> <td><h5> -- </h5>             <td>no seminar</td></tr>

  <tr><td>4</td>      <td>12.10.2023</td> <td><h5>Mert Albaba</h5>      <td>XSkill: Cross Embodiment Skill Discovery</td></tr>
  <tr><td>4</td>      <td>12.10.2023</td> <td><h5>Artur Grigorev</h5>   <td>GarmentCode: Programming Parametric Sewing Patterns</td></tr>
  
  <tr><td>5</td>      <td>19.10.2023</td> <td><h5>Egor Zakharov</h5>     <td>Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis</td></tr>
  <tr><td>5</td>      <td>19.10.2023</td> <td><h5>Lixin Xue</h5>        <td>Neuralangelo: High-Fidelity Neural Surface Reconstruction</td></tr>
  
  <tr><td>6</td>      <td>26.10.2023</td> <td><h5>Zijian Dong</h5>      <td>Rodin: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion</td></tr>
  <tr><td>6</td>      <td>26.10.2023</td> <td><h5>Zijian Dong</h5>      <td>AvatarVerse: High-quality & Stable 3D Avatar Creation from Text and Pose</td></tr>
  
  <tr><td>7</td>      <td>02.11.2023</td> <td><h5>Gengyan Li</h5>       <td>Mixture of Volumetric Primitives for Efficient Neural Rendering</td></tr>
  <tr><td>7</td>      <td>02.11.2023</td> <td><h5>Mert Albaba</h5>      <td>Ase: Large-scale reusable adversarial skill embeddings for physically simulated characters</td></tr>

  <tr><td>8</td>      <td>09.11.2023</td> <td><h5> -- </h5>             <td>no seminar</td></tr>

  <tr><td>9</td>      <td>16.11.2023</td> <td><h5> -- </h5>             <td>no seminar</td></tr>
  
  <tr><td>10</td>     <td>23.11.2023</td> <td><h5>Yufeng Zheng</h5>     <td>Multi-View Reconstruction using Signed Ray Distance Functions (SRDF)</td></tr>
  <tr><td>10</td>     <td>23.11.2023</td> <td><h5>Yufeng Zheng</h5>     <td>Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor</td></tr>
  
  <tr><td>11</td>     <td>30.11.2023</td> <td><h5>Hsuan-I Ho</h5>       <td>Learning Locally Editable Virtual Humans</td></tr>
  <tr><td>11</td>     <td>30.11.2023</td> <td><h5>Hsuan-I Ho</h5>       <td>Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models</td></tr>

  
  <tr><td>12</td>     <td>07.12.2023</td> <td><h5>Chen Guo</h5>         <td>Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition </td></tr>
  <tr><td>12</td>     <td>07.12.2023</td> <td><h5>Zicong Fan</h5>       <td>TOCH: Spatio-Temporal Object Correspondence to Hand for Motion Refinement</td></tr>

  
  <tr><td>13</td>     <td>14.12.2023</td> <td><h5> -- </h5>             <td>The eyes have it: An integrated eye and face model for photorealistic facial animation</td></tr>
  <tr><td>13</td>     <td>14.12.2023</td> <td><h5> -- </h5>             <td>Learning joint reconstruction of hands and manipulated objects</td></tr>

  <tr><td>14</td>     <td>21.12.2023</td> <td><h5> -- </h5>             <td>no seminar</td></tr>
  
</tbody></table>

<hr/>

-->