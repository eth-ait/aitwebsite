---
title: Machine Perception
ref: mp2024
description: 
semester: Spring 2024 
number: <a href="https://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?lerneinheitId=178576&semkez=2024S&ansicht=LEHRVERANSTALTUNGEN&lang=en">263-3710-00L</a>
lecturer: Otmar Hilliges, Stelian Coros, Jie Song, Xu Chen, Manuel Kaufmann, Marcel Buehler, Sammy Christen
head-ta: 
ta: Zicong Fan, Hsuan-I Ho, Chen Guo, Yufeng Zheng, Zijian Dong, Mert Albaba, Gengyan Li, Egor Zakharov, Chengwei Zheng, Seyedmorteza Sadat, Juan Zarate
assistants:
edoz: 
session-time-place: 
lecture-time-place: Wed 13:15 - 14:00 (HG F 1)<br/> Thu 12:15 - 14:00 (HG F 1)
exercise-time-place: Thu 14:15 - 16:00 (CAB G 11)<br/> Fri 14:15 - 16:00 (CAB G 11)
image: 
links: 
credits: 8
recordings: All recordings will be made available on the <a href="https://video.ethz.ch/lectures/d-infk/2024/spring/263-3710-00L.html">ETH Video Portal</a>.
contact: Please post all questions (regarding content, organization etc.) on <a href="https://moodle-app2.let.ethz.ch/enrol/index.php?id=22197">Moodle</a>.
---

<h3>Overview</h3>
<p>
    Recent developments in neural networks (aka “deep learning”) have drastically advanced the performance of machine perception systems in a variety of areas including computer vision, robotics, and human shape modeling This course is a deep dive into deep learning algorithms and architectures with applications to a variety of perceptual and generative tasks.
</p>

<hr/>

<a class="anchor" id="announcements"></a>
<h3>Announcements</h3>
<dl class="definitionlist">
    <dt>05.02.2024</dt><dd> Project descriptions have been added <a href="#projects"> here</a>! </dd>
    <dt>03.01.2024</dt><dd> More info coming soon! </dd>
</dl>

<hr/>

<a class="anchor" id="objectives"></a>
<h3>Learning Objectives</h3>
<p> Students will learn about fundamental aspects of modern deep learning approaches for perception and generation. Students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in learning-based computer vision, robotics, and shape modeling. The optional final project assignment will involve training a complex neural network architecture and applying it to a real-world dataset.
</p>
<p>The core competency acquired through this course is a solid foundation in deep-learning algorithms to process and interpret human-centric signals. In particular, students should be able to develop systems that deal with the problem of recognizing people in images, detecting and describing body parts, inferring their spatial configuration, performing action/gesture recognition from still images or image sequences, also considering multi-modal data, among others.
</p>
<p>We will focus on teaching: how to set up the problem of machine perception, the learning algorithms, network architectures, and advanced deep learning concepts in particular probabilistic deep learning models.
<br/>
The course covers the following main areas:<br/>
I) Foundations of Deep Learning.<br/>
II) Advanced topics like probabilistic generative modeling of data (latent variable models, generative adversarial networks, auto-regressive models, invertible neural networks).<br/>
III) Deep learning in computer vision, human-computer interaction, and robotics.
</p>
<hr/>

<a class="anchor" id="note"></a>
<h3>Lecture Notes</h3>
<p>You can download the lecture notes <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lecture_notes/mp_course_notes_2024.pdf">here</a> (you will need to log in with your ETH LDAP).
</p>
<p> These lecture notes are provided as a draft version for educational purposes only. The content presented herein is subject to change and may contain inaccuracies or errors. Grading for the course will be based on slides and the lecture materials.
</p>
<hr/>


<a class="anchor" id="schedule"></a>
<h3>Schedule</h3>

<p>Subject to change. Materials only available from within ETH network.</p>


<table>

    <tr>
        <th>Wk.</th><th>Date</th> <th>Content</th><th>Material</th> <th>Exercise Session</th>
    </tr>
    <tbody>
    <tr>
        <td>1</td>
        <td> 21.02 </td>
        <td>
            <h5>Deep Learning Introduction</h5><p>Class content &amp; admin</p>
        </td>
        <td>
        <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l01-Intro.pdf">slides</a><br/>
        </td>
        <td>
         </td>
    </tr>

    <tr>
        <td>1</td>
        <td> 22.02 </td>
        <td>
            <h5>-- No Class --</h5>
        </td>
        <td></td>
        <td></td>
    </tr>

 
    <tr>
        <td>2</td>
        <td>28.02 <br> 29.02</td>
        <td>
            <h5>Training Neural Networks</h5><p>Backpropagation <br> Feedforward Networks, <br>  Representation Learning</p>
        </td>

        <td>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l02a-Intro-NN.pdf">slides pt. I</a><br/>
            <!-- <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2023-MP-l02a-Intro-NN-annotated.pdf">slides pt. I (annotated)</a><br/> -->
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l02b-Function_Approximation_Backpropagation.pdf">slides pt. II</a><br/>
            <br/>
            <a class="a-text-ext" href="https://colab.research.google.com/drive/1bycbm85pTwnL7Izw5WHpdvkA63rdedE6?usp=sharing">Perceptron Visualization Notebook</a><br/> 
            <!--
            <a class="a-vid" href="https://ethz.zoom.us/rec/share/p2fodabW9EuSTdAVQtoXb0xOGb0PWaZT0kbQWZr_-0o_622K9uMbeDZeDpbTpZ15.XepCi2ydOU5mLGSP">recording part I</a><br/>
            <br/>
            <a class="a-vid" href="https://ethz.zoom.us/rec/share/HkGJYgspQvEVSQ1SvDuzae5PVpnOQZCB8gMyO1aiysmNUE_xSEWt8s0yVpqElOti.saA0w8P8j4rI9G8H">recording part II</a><br/>-->
        </td>
        <td>
            <p><b>Tutorial</b> Implement your own MLP</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/tutorials/implement_your_own_mlp.pdf">slides</a><br/>
            <a class="a-text-ext" href="https://drive.google.com/file/d/1J2nhaQvmG_AFGLB6VI8jwE6bIXwbgfRR/view?usp=sharing" target="_blank">XOR Notebook</a><br/>
            <a class="a-text-ext" href="https://colab.research.google.com/drive/1DtaWl0nMqi0fA8aK7PImV7fZCfpKK2A6?usp=sharing" target="_blank">XOR Solutions</a><br/> 
            <a class="a-text-ext" href="https://colab.research.google.com/drive/1f8HgYeHR7r9JhtgmCeOc5xWAlcgIAjkK?usp=sharing" target="_blank">Eye-Gaze Notebook</a><br/>
            <a class="a-text-ext" href="https://colab.research.google.com/drive/1wV_n8MtrL4IzQt-dbJx2F4XKTYP39bSt?usp=sharing" target="_blank">Eye-Gaze Solutions</a><br/>
            <p><b>Tutorial</b> Linear Regr.</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/tutorials/linear_regression.pdf">slides</a><br/>
            <a class="a-text-ext" href="https://colab.research.google.com/drive/113onB8fGx7Apto2OIA4YRKthYp29nSkE?usp=sharing">Linear Regression Notebook</a><br/>
            <!-- <br/> -->
            <p><b>Pen &amp; Paper</b> Backprop.</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex2_instructions.pdf">exercise</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex2_solutions.pdf">exercise solution</a><br/> 

        </td>
    </tr>


    <tr>
        <td>3</td>
        <td>06.03. <br> 07.03.</td>
        <td>
            <h5>Convolutional Neural Networks</h5>
        </td>
        <td>
            <p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l03a-CNN.pdf">slides pt. I</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l03b-CNN.pdf">slides pt. II</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l04-Fully-CNN.pdf">slides pt. III</a>
            </p>
            <p>Additional material:
            <br/>
            <a class="a-text-ext" href="https://files.ait.ethz.ch/teaching/courses/2021-SS-Machine-Perception/downloads/reading_materials/RSVP.mp4">RSVP</a>
            <br/>
            <a class="a-text-ext" href="https://files.ait.ethz.ch/teaching/courses/2021-SS-Machine-Perception/downloads/reading_materials/Cortical-Neuron.mp4">Cortical Neuron</a> -->
            </p>

        </td>
        <td>
            <p><b>Tutorial</b> CNNs in Pytorch</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/tutorials/cnn.pdf">slides</a><br/>
            <a class="a-text-ext" href="https://colab.research.google.com/drive/1lXfwxA6wlQ3na9pXeqUVbi_EEtWAIegW">CNN Notebook</a><br/><br/>

            <p><b>Pen &amp; Paper</b> CNN</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex3_instructions.pdf">exercise</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex3_solutions.pdf">exercise solution</a><br/> 
        </td> 

    </tr>


     <tr>
        <td>4</td>
        <td>14.03.</td>
        <td>
            <h5>Recurrent Neural Networks</h5><p>LSTM, GRU, Backpropagation through time</p>
        </td>
        <td>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l05-RNN.pdf">slides</a><br/>
        </td>

        <td>
            <p><b>Tutorial</b> RNNs in Pytorch</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/tutorials/rnn.pdf">slides</a><br/>
            <a class="a-text-ext" href="https://colab.research.google.com/drive/1cUbVzcXMCquf5xhfTOPnxIrqgxA1Lr8k">RNN Notebook</a><br/>
            <br/>
            <p><b>Pen &amp; Paper</b> RNN</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex4_instructions.pdf">exercise</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex4_solutions.pdf">exercise solution</a><br/>
        </td> 

    </tr>

    <tr>
        <td>5</td>
        <td>20.03. <br> 21.03 </td>
        <td>
            <h5>Generative Models Pt. I: Latent Variable Models </h5><p>Variational Autoencoders, etc.</p>
        </td>
        <td>
        <p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l06a-VAE.pdf">slides pt. I</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/lectures/2024-MP-l06b-VAE.pdf">slides pt. II</a>
        </p>
        </td>
        
        <td>
         
            <p><b>Class</b> Tips for Training I (Regularization)</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/tutorials/6_Regularization_tutorial.pdf">slides</a><br/>
            <br/>
            <p><b>Pen &amp; Paper</b> VAE</p>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex5_vae_instructions.pdf">exercise</a><br/>
            <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/pp/ex5_vae_solutions.pdf">exercise solution</a><br/> 
        </td> 


    </tr>
        
</tbody></table> 


<hr/>

<a class="anchor" id="exercises"></a>

<h3>Exercise Sessions</h3>
     <p>
        Please refer to the <a href="#schedule">above schedule once available </a> for an overview of the planned exercise slots. We will have three different types of activities in the exercise sessions:
        <ol>
            <li><b>Tutorial:</b> Interactive programming tutorial in Python taught by a TA. Code will be made available.</li>
            <li><b>Class:</b> Lecture-style class taught by a TA to give you some tips on how to train your neural network in practice.</li>
            <li><b>Pen &amp; Paper</b>: Pen &amp; paper exercises that are not graded but are helpful to prepare for the written exam. Solutions will be published on the website a week after the release and discussed in the exercise session if desired.</li>
        </ol>
    </p>
    <!--<p>
        The tutorials and classes cover the same content on Thursday and Friday. You can decide which day you want to attend.
        The Thursday session is in person (CAG G 11) and has 190 seats.
        The Friday session is on zoom and has no limit on the number of students.
    </p>
    <p>
    Please find the zoom link for the exercises sessions on <a href="https://ait.ethz.ch/teaching/courses/2022-SS-Machine-Perception/downloads/lectures/2022-MP-l01-Intro.pdf" title="Slides" target="_blank">slide 39</a> of the first week's slide deck.
    </p> -->

    <!-- <p>The exercises are meant to help you understand the course's content more in-depth and to prepare you for the <a href="#projects">graded multi-week project</a>. Exercise sessions are primarily scheduled until week 8 so that you have time to work on the project after week 8.</p>

-->
<hr/>
<a class="anchor" id="projects"></a>
<h3>Project</h3>
<h4>Overview</h4>
<p>
    There will be a multi-week project that gives you the opportunity to have some hands-on experience with training a neural network for a concrete application.
</p>

<p>
    The project grade will be determined by two factors: 1) a competitive part based on how well your model fairs compared to your fellow students' models and 2) the idea/novelty/innovativeness of your approach based on a written report to be handed in by the project deadline. For each project there will be baselines available that guarantee a certain grade for the competitive part if you surpass them. The competition will be hosted on an online platform.
</p>

<p>
Check out the project descriptions <a class="a-pdf" href="https://files.ait.ethz.ch/teaching/courses/2024-SS-Machine-Perception/downloads/projects/mp_project.pdf">here</a> (you will need to log in with your ETH LDAP).
</p>
<!-- 
<p>Project registrations are open! Please sign your group up
<a href="https://forms.gle/KxxGDSJPJmU2fX8t9" target="_blank" title="Project Registration Form">here</a>. Registrations will <b>close on March 23rd, 11:59pm</b>, please make sure to sign up in time.</dd>
</p> -->


<!--
<hr>
<a class="anchor" id="exams"></a>
<h3>Exam</h3>
<p>
To give you a rough idea what to expect for the exam, we release a mock exam which you can download here:
  <ul>
    <li>
    </li>
    <li>
    </li>
  </ul>
</p>
-->


<!-- <h4>Submission</h4>
    <p>
    For the final submission, please write a report (using <a href="https://www.overleaf.com/read/tzvrpffsdrxx" target="_blank">this LaTeX template</a>) and upload your report along with your code. Details about the submission are announced later. We will re-train and re-evaluate your model. Hence, your submission should provide easy-to-follow instructions that let us reproduce your final score on the leaderboard. Please include a readme with the submission with respective instructions how to train and evaluate your model. For submissions for which it is not possible to reproduce the results, grades will be penalized accordingly.
    </p> -->

<!-- <h4>Grading</h4>
    <p>
    This project constitutes 40% of the final course grade. Project grades will be determined by taking the average of public and private scores. We will provide two baselines. Beating the easy baseline guarantees a grade of 4. As we want to encourage novel solutions and ideas, we also ask you to write a short report (3 pages, excluding references) detailing the model you used for the final submission and your contributions. Depending on this, we will weigh the grade determined by your performance w.r.t. the baselines. In other words, the grade computed as mentioned above can go up or down, depending on the contributions of your project. If you passed the easy baseline, your final grade cannot go lower than 4 after the weighting.
    </p> -->
<hr/>
<a class="anchor" id="registration"></a>
<h3>Registration as Non-primary Target Group</h3>
<p>
Registrations have been closed.
</p>

<hr/>
